#!/bin/sh

set -u -x
BUCKET=${STACK_NAME}-${PLATFORM}-dce-test-emr
CLUSTER=${STACK_NAME}-${PLATFORM}-spark-emr
CLUSTER_ID=$(aws emr list-clusters --region=eu-west-1 --active | jq '.[][] | select(.Name == "'${CLUSTER}'") | .Id' | tr -d '"')

aws s3 cp --recursive s3://$BUCKET ./jobs
git clone git@bitbucket.org:saffrondigital/dce_spark_jobs.git repo

rm -rf repo/.git
CHANGES=$(git diff --no-index --name-only jobs repo | grep -v /dev/null)
CHANGED_JOBS=$(echo $CHANGES | grep py)

# Copy changed files to the bucket
for change in ${CHANGES}; do
    aws s3 cp --acl "authenticated-read" $change s3://${BUCKET}/
done

var_date=$(date -d "yesterday 13:00 " '+%Y-%m-%d' )

{{ range $job := sections }}{{ if ne $job "common" }}
echo ${CHANGED_JOBS} | grep -qw {{ $job }}
if [ "$?" -eq 0 ]; then
    aws emr add-steps --region eu-west-1 --cluster-id ${CLUSTER_ID} --steps Type=Spark,Name="dce-{{ $job }}-job",ActionOnFailure=CONTINUE,Args=[--class, {{ section $job "name"}} ,--packages,{{ config "common.packages" }}, --config,{{ config "common.awsSecretAccessKey" }}, --config,{{ config "common.awsAccessKeyId" }},--config,{{ config "common.jdbc_url" }},--config,{{ config "common.username" }},--config,{{ config "common.password" }}, --repositories,{{ config "common.repositories" }}, ${BUCKET}/{{ config "common.jar" }},--path,{{ config "common.path" }}/var_date/*/* ]
fi
{{ end }}{{ end }}

